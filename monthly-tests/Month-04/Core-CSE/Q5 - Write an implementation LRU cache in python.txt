Q5. Explain LRU cache and its implementation by taking some examples and explaining all
steps

ANS:
A Least Recently Used (LRU) Cache organizes items in order of use, allowing you to quickly identify which item hasn't been used for the longest amount of time.

Picture a clothes rack, where clothes are always hung up on one side. To find the least-recently used item, look at the item on the other end of the rack.

Under the hood, an LRU cache is often implemented by pairing a doubly linked list with a hash map.

We use two data structures to implement an LRU Cache. 
 

Queue which is implemented using a doubly linked list. The maximum size of the queue will be equal to the total number of frames available (cache size). The most recently used pages will be near front end and least recently pages will be near the rear end. 
 
A Hash with page number as key and address of the corresponding queue node as value.
When a page is referenced, the required page may be in the memory. If it is in the memory, we need to detach the node of the list and bring it to the front of the queue. 
If the required page is not in memory, we bring that in memory. In simple words, we add a new node to the front of the queue and update the corresponding node address in the hash. If the queue is full, i.e. all the frames are full, we remove a node from the rear of the queue, and add the new node to the front of the queue.

Example Code:-
class LRUCache:

  def _init_(self, capacity):
    self.capacity = capacity
    self.cache = set()
    self.cache_vals = LinkedList()

  def set(self, value):
    node = self.get(value)
    if node == None:
      if(self.cache_vals.size >= self.capacity):
        self.cache_vals.insert_at_tail(value)
        self.cache.add(value)
        self.cache.remove(self.cache_vals.get_head().data)
        self.cache_vals.remove_head()
      else:
        self.cache_vals.insert_at_tail(value)
        self.cache.add(value)
    
    else:
      self.cache_vals.remove(value)
      self.cache_vals.insert_at_tail(value)
  
  def get(self, value):
    if value not in self.cache:
      return None
    else:
      i = self.cache_vals.get_head()
      while i is not None:
        if i.data == value:
          return i
        i = i.next

  def printcache(self):
    node = self.cache_vals.get_head()
    while node != None :
      print(str(node.data) + ", ")
      node = node.next
      
cache1 = LRUCache(4)
cache1.set(10)
cache1.printcache()

cache1.set(15)
cache1.printcache()

cache1.set(20)
cache1.printcache()

cache1.set(25)
cache1.printcache()

cache1.set(30)
cache1.printcache()

cache1.set(20)
cache1.printcache()